知识图谱的异构性
- 从知识图谱构建的角度
	- 早期知识工程的理想是构建统一的知识库
	- 人类知识体系复杂
	- 知识会随时间演化
	- 同一领域内不同组织构建不同知识库
	- 不同领域往往根据不同的需求独立构建知识库
- 从知识图谱应用角度
	- 不同的系统采用的知识是异构的，它们之间的信息交互便无法正常进行
	- 大量的共指问题会给知识图谱的应用造成负面影响

![[f2236541864dd3c89879611b73be759f.png]]

知识融合是解决知识图谱异构问题的有效途径。知识融合的核心问题在于**映射的生成**。

语言层面和模型层面的不匹配是导致知识图谱异构的本质原因

知识融合旨在将不同的知识图谱融合为统一、一致、简洁的形式，为使用不同知识图谱的应用程序之间的交互建立互操作性。

- 本体匹配（Ontology Matching）
	- 发现（模式层）等价或相似的类、属性或关系
		- 本体对齐、本体映射
- 实体对齐（Entity Alignment）
	- 发现指称真实世界相同对象的不同实例
		- 实体消解、实例匹配
- 知识融合：即合并两个知识图谱，基本的问题都是研究怎样将来自多个来源的关于同一个实体或概念的描述信息融合起来


## 概念层融合——本体匹配
![[9df7b017f95f1642f0fd55814c509292.png]]
#### 术语匹配方法
术语匹配的原理
- 核心思想： 将文档变为向量的形式，通过向量相似度实现文档匹配
- 本体中的概念和属性往往含有大量的文本信息
- 将待匹配的对象的相关文本组成成文档的形式，再转换为文档向量

基于字符串的方法：直接比较表示本体成分的术语的字符串结构
规范化
- 大小写： 字符串中的每个符号转换为大写字母或小写字母的形式
- 消除变音符： Montréal 替换为Montreal；
- 空白正规化： 所有的空白字符（如空格、制表符和回车等）转换为单个的空格符
- 连接符正规化：正规化单词的换行连接符等
- 消除标点： 在不考虑句子的情况下要去除标点符号
- 消除无用词： 如 “to” 和 “a

相似度度量⽅法
![[177e0db47dd62eb2ef249cb6e8dc55d2.png]]
- Levenshtein 距离，即最小编辑距离，目的是用最少的编辑操作将一个字符串转换成另一个。
	- 动态规划问题$$\left.\left\{\begin{array}{ccc}D(0,0)=&0\\D(i,0)=&D(i-1,0)+1&1<i\leq N\\D(0,j)=&D(0,j-1)+1&1<j\leq M\end{array}\right.\right. \ \ \ \ \ , \  \ D(i,j)=min\left\{\begin{array}{r}D(i-1,j)+1\\D(i,j-1)+1\\D(i-1.j-1)+1\\\end{array}\right.$$
- 汉明距离$$\delta(s,t)=1-\frac{(\sum_{i=1}^{\min(|s|,|t|)}s[i]\neq t[i])+\parallel s\mid-\mid t\parallel}{\max(\mid s\mid,\mid t\mid)}$$
- 子串相似度，任意两个字符串 s 和$\iota$间的相似度$\delta$ ,令 $x$ 为 $s$ 和$t$的最大共同子串，则它们的子串相似度为：$$\delta(s,t)=\frac{2\mid x\mid}{\mid s\mid+\mid t\mid}$$
- Dice系数用于度量两个集合的相似性，因为可以把字符串理解为一种集合$$sim_{Dice}(s,t)=\frac{2|S\:cap\ T|}{|S|+|T|}$$
- Jaccard 系数适合处理短文本的相似度$$sim_{Jaccard}(s,t)=\frac{|S\cap T|}{|S\cup T|}$$
	- 上述还可以用n-gram分割单词，用n-gram分割句子等来构建集合，计算相似度。
- TF-IDF主要用来评估某个字或者用某个词对一个文档的重要程度。

**虚拟文档**
虚拟文档是一种抽象的表示方式，用于描述和组织信息。它不是实际存在的文档，而是通过将相关信息聚合在一起，形成一个逻辑上的整体。

虚拟文档的构建
- 概念的语言学描述：本地名、标签、注释
- 匿名结点的语言学描述：前向邻居的语言学描述
- 概念的邻居：主语邻居、谓语邻居、宾语邻居
- 概念的虚拟文档：自身+邻居结点
#### 结构匹配

- 核心思想： 利用本体的结构信息来弥补文本信息量不足的情况
- 本体中的概念和属性往往有大量相关的其他概念和属性，组成了一种图结构
- 结构匹配器不采用图匹配技术，后者代价高昂且效果不理想

间接的结构匹配器：在术语匹配器中考虑结构信息，如邻居、上下文、属性等
直接的结构匹配器：图匹配复杂度高，无法直接使用；**相似度传播模型的变体很有效**

Anchor-Prompt：通过一组已知匹配的元素（锚点）来推断和扩展其他元素的匹配关系。以两个本体中已配对的术语对集合为输入，将本体视作图结构（类别作为节点，槽作为边），通过分析已配对节点对之间路径上节点的相似性来生成新的匹配术语对(anchor)。![[7d25b14e06d26a3a62ca2cd00e28c01a.png]]

上图展示了一个简例，初始输入的Anchor集合中包含(A,B)和(H,G)两组已配对术语，A与H之间存在一条长度为3的路径，B与G之间存在一条长度为3的路径，那么我们有理由认为这两条路径上对应的术语对(C,D)与(D,F)可能存在相似性。


大规模本体匹配通常采用先分块后匹配的方式

## 实例层融合——实体对齐

实体对齐侧重发现指称真实世界相同对象的不同实例

- 传统方法
	- 等价关系推理 $\langle s,owl:sameAs,o\rangle\to\langle s,o\rangle\in S \ and \ \langle o,s\rangle\in S$
	- 相似度计算 见上述
- 基于表示学习的方法
	- Embedding-based—基于表示学习技术，将知识图谱中的实体和关系都映射成低维空间向量，直接用数学表达式计算实体间相似度
		- 先用单一网络的嵌入模型分别训练两个网络，然后用一些预先匹配好的实体训练一个线性变换对齐两个向量空间。
			- 合并预先匹配好的实体，把两个网络合并为一个网络，用单一网络的嵌入表示进行嵌入。
			- 在TransE基础上增加一个实体对齐损失，采用的线性转换矩阵实现实体对齐$$L=\sum_{(h,r,t)\in S}\sum_{(h^{\prime},r,t^{\prime})\in S_{(h,r,t)}^{\prime}}\{[\gamma+d(h+r,t)-d(h^{\prime}+r,t^{\prime})]_{+}+\\\lambda_1\sum_{y\in\{h,h^{\prime},r,t,t^{\prime}\}}|||y||_2-1|\}+\lambda_2\sum_{(e_i,e_i^{\prime})\in A}||M_de_i-e_i^{\prime}||_2$$也可以用距离对齐或者转移向量等对齐![[2d0a2f8800afe8b232f4607fb7ea5380.png]]
- Silk是一个基于Python开发的集成异构数据源的开源框架![[e6207055350422bc1eca68746dfe2d40.png]]
- OpenEA一个开源的基于Tensorflow的实体对齐框架
- EAKit一个轻量级基于PyTorch的实体对齐框架



## 知识融合前沿发展

- 无监督对齐——不一定都有预先匹配好的实体

- 多视角嵌入——单一模型的嵌入能力往往不足以对齐两个网络

- 嵌入表示增强——改进现有的嵌入表示模型并用于对齐，现有的嵌入模型会让度（节点的邻居个数）相似的节点更接近

- 超大规模对齐——上亿个节点的网络对齐